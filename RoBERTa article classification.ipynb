{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-24T20:05:31.519727Z","iopub.execute_input":"2024-04-24T20:05:31.520206Z","iopub.status.idle":"2024-04-24T20:05:31.527177Z","shell.execute_reply.started":"2024-04-24T20:05:31.520175Z","shell.execute_reply":"2024-04-24T20:05:31.525907Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import transformers\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\nfrom transformers import RobertaTokenizerFast, RobertaModel, RobertaForSequenceClassification\nfrom transformers import PretrainedConfig","metadata":{"execution":{"iopub.status.busy":"2024-04-24T20:05:32.138803Z","iopub.execute_input":"2024-04-24T20:05:32.139823Z","iopub.status.idle":"2024-04-24T20:05:39.679434Z","shell.execute_reply.started":"2024-04-24T20:05:32.139771Z","shell.execute_reply":"2024-04-24T20:05:39.678356Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# model = RobertaModel.from_pretrained(\"roberta-base\")\n# PretrainedConfig()\nmodel = RobertaForSequenceClassification.from_pretrained('roberta-base', num_labels=11)\ntokenizer = RobertaTokenizerFast.from_pretrained('roberta-base', max_length = 512)","metadata":{"execution":{"iopub.status.busy":"2024-04-24T20:23:41.969882Z","iopub.execute_input":"2024-04-24T20:23:41.970358Z","iopub.status.idle":"2024-04-24T20:23:42.631729Z","shell.execute_reply.started":"2024-04-24T20:23:41.970291Z","shell.execute_reply":"2024-04-24T20:23:42.630631Z"},"trusted":true},"execution_count":42,"outputs":[{"name":"stderr","text":"Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"from datasets import load_dataset\n\ndataset = load_dataset(\"ccdv/arxiv-classification\")","metadata":{"execution":{"iopub.status.busy":"2024-04-24T20:05:45.611369Z","iopub.execute_input":"2024-04-24T20:05:45.611798Z","iopub.status.idle":"2024-04-24T20:07:05.836162Z","shell.execute_reply.started":"2024-04-24T20:05:45.611760Z","shell.execute_reply":"2024-04-24T20:07:05.835243Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/datasets/load.py:1461: FutureWarning: The repository for ccdv/arxiv-classification contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/ccdv/arxiv-classification\nYou can avoid this message in future by passing the argument `trust_remote_code=True`.\nPassing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/3.80k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"92a3d901d9134d13a1c5b8b1bd903a49"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading readme:   0%|          | 0.00/1.68k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"93a22d5c9a0d4f3b82b288cfeed53c8f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/1.71G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"581be8fbf44946cb973a61a4999323d6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/150M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0e1e9c70503a4e239163f8e2316c7217"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/146M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9c53381617f946eeb47368c2cdec6e02"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"998165c0b35c4c548ea357fc92349807"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e0ba1595d2eb4a0ca22197d5012a165b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7ce1087c267e410495af62ffc133f838"}},"metadata":{}}]},{"cell_type":"markdown","source":"let's learn the names of the classes","metadata":{}},{"cell_type":"code","source":"dataset['train'].features","metadata":{"execution":{"iopub.status.busy":"2024-04-24T20:07:05.838027Z","iopub.execute_input":"2024-04-24T20:07:05.838413Z","iopub.status.idle":"2024-04-24T20:07:05.846332Z","shell.execute_reply.started":"2024-04-24T20:07:05.838384Z","shell.execute_reply":"2024-04-24T20:07:05.845263Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"{'text': Value(dtype='string', id=None),\n 'label': ClassLabel(names=['math.AC', 'cs.CV', 'cs.AI', 'cs.SY', 'math.GR', 'cs.CE', 'cs.PL', 'cs.IT', 'cs.DS', 'cs.NE', 'math.ST'], id=None)}"},"metadata":{}}]},{"cell_type":"code","source":"model","metadata":{"execution":{"iopub.status.busy":"2024-04-24T20:07:05.848073Z","iopub.execute_input":"2024-04-24T20:07:05.848438Z","iopub.status.idle":"2024-04-24T20:07:05.862196Z","shell.execute_reply.started":"2024-04-24T20:07:05.848410Z","shell.execute_reply":"2024-04-24T20:07:05.861344Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"RobertaForSequenceClassification(\n  (roberta): RobertaModel(\n    (embeddings): RobertaEmbeddings(\n      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n      (position_embeddings): Embedding(514, 768, padding_idx=1)\n      (token_type_embeddings): Embedding(1, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): RobertaEncoder(\n      (layer): ModuleList(\n        (0-11): 12 x RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n  )\n  (classifier): RobertaClassificationHead(\n    (dense): Linear(in_features=768, out_features=768, bias=True)\n    (dropout): Dropout(p=0.1, inplace=False)\n    (out_proj): Linear(in_features=768, out_features=11, bias=True)\n  )\n)"},"metadata":{}}]},{"cell_type":"markdown","source":"As we see, classifier changed to our implementation. So we are ready to finetune the model.","metadata":{}},{"cell_type":"markdown","source":"### Tokenizing data\nThe 'text' contains a lot of unneded information such as author, publication information and etc. All we need is introduction so we can preprocess it and narrow to the ontext size of 512. However, here i'll test is it able to learn with all of this information. So the only thing applied is truncation.\n","metadata":{}},{"cell_type":"code","source":"train_len = 3000\ntrain_data = dataset['train'].select(list(range(train_len)))\ntest_data = dataset['test'].select(list(range(train_len//10)))","metadata":{"execution":{"iopub.status.busy":"2024-04-24T20:19:00.092866Z","iopub.execute_input":"2024-04-24T20:19:00.093276Z","iopub.status.idle":"2024-04-24T20:19:00.123602Z","shell.execute_reply.started":"2024-04-24T20:19:00.093244Z","shell.execute_reply":"2024-04-24T20:19:00.122546Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"def rename_column(example):\n#     new_label = example['label'] % 2\n    new_label = example['label'] \n    example['labels'] = new_label\n    del example['label']\n    return example\n\ndef tokenize_fn(text):\n    tokenized =  tokenizer(text['text'], \n                   truncation = True, \n                   max_length = 512, \n                   return_tensors='pt',\n                  )\n    \n    return tokenized","metadata":{"execution":{"iopub.status.busy":"2024-04-24T20:19:00.853955Z","iopub.execute_input":"2024-04-24T20:19:00.854342Z","iopub.status.idle":"2024-04-24T20:19:00.861713Z","shell.execute_reply.started":"2024-04-24T20:19:00.854313Z","shell.execute_reply":"2024-04-24T20:19:00.860745Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"train_data = train_data.map(tokenize_fn, batched = True)\ntest_data = test_data.map(tokenize_fn, batched = True)\n\ntrain_data = train_data.map(rename_column)\ntest_data = test_data.map(rename_column)\n\ntrain_data.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\ntest_data.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])","metadata":{"execution":{"iopub.status.busy":"2024-04-24T20:19:01.908101Z","iopub.execute_input":"2024-04-24T20:19:01.909073Z","iopub.status.idle":"2024-04-24T20:20:41.295291Z","shell.execute_reply.started":"2024-04-24T20:19:01.909031Z","shell.execute_reply":"2024-04-24T20:20:41.294263Z"},"trusted":true},"execution_count":34,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/3000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3959cf83c793494b9232fb1d038ae918"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/300 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e90eb804e5774c1c9c251c26ef112534"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/3000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9dab04e0d51f4b96921c8380bb2008fb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/300 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"32f60d73d03b45dda8e7c35a3e5000a0"}},"metadata":{}}]},{"cell_type":"code","source":"train_data","metadata":{"execution":{"iopub.status.busy":"2024-04-24T20:20:41.297034Z","iopub.execute_input":"2024-04-24T20:20:41.297386Z","iopub.status.idle":"2024-04-24T20:20:41.304075Z","shell.execute_reply.started":"2024-04-24T20:20:41.297357Z","shell.execute_reply":"2024-04-24T20:20:41.302803Z"},"trusted":true},"execution_count":35,"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['text', 'input_ids', 'attention_mask', 'labels'],\n    num_rows: 3000\n})"},"metadata":{}}]},{"cell_type":"markdown","source":"### Finetune","metadata":{}},{"cell_type":"code","source":"# define accuracy metrics\nimport torch\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\nimport numpy as np\nfrom sklearn.metrics import accuracy_score, precision_recall_fscore_support\nfrom tqdm import tqdm\nfrom datasets import load_metric\n\nmetric = load_metric('accuracy')\n\ndef compute_metrics(eval_pred):\n    predictions, labels = eval_pred\n    predictions = np.argmax(predictions, axis=1)\n    return metric.compute(predictions=predictions, references=labels)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-24T20:28:39.269500Z","iopub.execute_input":"2024-04-24T20:28:39.270464Z","iopub.status.idle":"2024-04-24T20:28:39.431574Z","shell.execute_reply.started":"2024-04-24T20:28:39.270428Z","shell.execute_reply":"2024-04-24T20:28:39.430355Z"},"trusted":true},"execution_count":51,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/datasets/load.py:756: FutureWarning: The repository for accuracy contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/accuracy/accuracy.py\nYou can avoid this message in future by passing the argument `trust_remote_code=True`.\nPassing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import TrainingArguments, Trainer\n\ntraining_args = TrainingArguments(\n    output_dir = '/kaggle/working/results',\n    num_train_epochs=3,    \n    evaluation_strategy=\"steps\",\n    eval_steps=25,\n    logging_strategy=\"steps\",\n    logging_steps=25,\n    logging_dir='/kaggle/working/logs',\n    report_to = 'none',\n)","metadata":{"execution":{"iopub.status.busy":"2024-04-24T20:28:42.521812Z","iopub.execute_input":"2024-04-24T20:28:42.522180Z","iopub.status.idle":"2024-04-24T20:28:42.551736Z","shell.execute_reply.started":"2024-04-24T20:28:42.522153Z","shell.execute_reply":"2024-04-24T20:28:42.550684Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"# instantiate the trainer class and check for available devices\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    compute_metrics=compute_metrics,\n    train_dataset=train_data,\n    eval_dataset=test_data, \n)\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\ndevice","metadata":{"execution":{"iopub.status.busy":"2024-04-24T20:28:42.912701Z","iopub.execute_input":"2024-04-24T20:28:42.913094Z","iopub.status.idle":"2024-04-24T20:28:42.935712Z","shell.execute_reply.started":"2024-04-24T20:28:42.913054Z","shell.execute_reply":"2024-04-24T20:28:42.934628Z"},"trusted":true},"execution_count":53,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \ndataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n  warnings.warn(\n","output_type":"stream"},{"execution_count":53,"output_type":"execute_result","data":{"text/plain":"'cuda'"},"metadata":{}}]},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-04-24T20:28:43.883947Z","iopub.execute_input":"2024-04-24T20:28:43.884782Z","iopub.status.idle":"2024-04-24T20:40:46.122682Z","shell.execute_reply.started":"2024-04-24T20:28:43.884742Z","shell.execute_reply":"2024-04-24T20:40:46.121653Z"},"trusted":true},"execution_count":54,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1125' max='1125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1125/1125 12:01, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>25</td>\n      <td>1.162600</td>\n      <td>1.277125</td>\n      <td>0.543333</td>\n    </tr>\n    <tr>\n      <td>50</td>\n      <td>1.094100</td>\n      <td>1.210027</td>\n      <td>0.576667</td>\n    </tr>\n    <tr>\n      <td>75</td>\n      <td>0.974200</td>\n      <td>1.144572</td>\n      <td>0.700000</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>0.908200</td>\n      <td>1.231181</td>\n      <td>0.506667</td>\n    </tr>\n    <tr>\n      <td>125</td>\n      <td>1.132300</td>\n      <td>0.917786</td>\n      <td>0.716667</td>\n    </tr>\n    <tr>\n      <td>150</td>\n      <td>1.028600</td>\n      <td>1.072621</td>\n      <td>0.643333</td>\n    </tr>\n    <tr>\n      <td>175</td>\n      <td>1.090800</td>\n      <td>0.842183</td>\n      <td>0.746667</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>1.089400</td>\n      <td>0.902441</td>\n      <td>0.733333</td>\n    </tr>\n    <tr>\n      <td>225</td>\n      <td>1.003400</td>\n      <td>0.945321</td>\n      <td>0.723333</td>\n    </tr>\n    <tr>\n      <td>250</td>\n      <td>0.882900</td>\n      <td>0.886337</td>\n      <td>0.740000</td>\n    </tr>\n    <tr>\n      <td>275</td>\n      <td>0.914100</td>\n      <td>0.926985</td>\n      <td>0.730000</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>1.045700</td>\n      <td>0.988990</td>\n      <td>0.736667</td>\n    </tr>\n    <tr>\n      <td>325</td>\n      <td>0.814800</td>\n      <td>0.855394</td>\n      <td>0.736667</td>\n    </tr>\n    <tr>\n      <td>350</td>\n      <td>0.841900</td>\n      <td>0.873360</td>\n      <td>0.746667</td>\n    </tr>\n    <tr>\n      <td>375</td>\n      <td>0.999300</td>\n      <td>0.877181</td>\n      <td>0.750000</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>0.686400</td>\n      <td>0.854289</td>\n      <td>0.763333</td>\n    </tr>\n    <tr>\n      <td>425</td>\n      <td>0.656700</td>\n      <td>0.856734</td>\n      <td>0.773333</td>\n    </tr>\n    <tr>\n      <td>450</td>\n      <td>0.930700</td>\n      <td>0.686337</td>\n      <td>0.796667</td>\n    </tr>\n    <tr>\n      <td>475</td>\n      <td>0.661800</td>\n      <td>0.910461</td>\n      <td>0.756667</td>\n    </tr>\n    <tr>\n      <td>500</td>\n      <td>0.626700</td>\n      <td>0.653475</td>\n      <td>0.796667</td>\n    </tr>\n    <tr>\n      <td>525</td>\n      <td>0.659200</td>\n      <td>0.796408</td>\n      <td>0.786667</td>\n    </tr>\n    <tr>\n      <td>550</td>\n      <td>0.736100</td>\n      <td>0.781276</td>\n      <td>0.796667</td>\n    </tr>\n    <tr>\n      <td>575</td>\n      <td>0.660200</td>\n      <td>0.662936</td>\n      <td>0.796667</td>\n    </tr>\n    <tr>\n      <td>600</td>\n      <td>0.611500</td>\n      <td>0.640387</td>\n      <td>0.806667</td>\n    </tr>\n    <tr>\n      <td>625</td>\n      <td>0.668000</td>\n      <td>0.683101</td>\n      <td>0.793333</td>\n    </tr>\n    <tr>\n      <td>650</td>\n      <td>0.696500</td>\n      <td>0.683665</td>\n      <td>0.803333</td>\n    </tr>\n    <tr>\n      <td>675</td>\n      <td>0.620500</td>\n      <td>0.715578</td>\n      <td>0.790000</td>\n    </tr>\n    <tr>\n      <td>700</td>\n      <td>0.478500</td>\n      <td>0.663918</td>\n      <td>0.826667</td>\n    </tr>\n    <tr>\n      <td>725</td>\n      <td>0.604000</td>\n      <td>0.589680</td>\n      <td>0.833333</td>\n    </tr>\n    <tr>\n      <td>750</td>\n      <td>0.668200</td>\n      <td>0.619862</td>\n      <td>0.833333</td>\n    </tr>\n    <tr>\n      <td>775</td>\n      <td>0.435300</td>\n      <td>0.637358</td>\n      <td>0.816667</td>\n    </tr>\n    <tr>\n      <td>800</td>\n      <td>0.396800</td>\n      <td>0.652737</td>\n      <td>0.826667</td>\n    </tr>\n    <tr>\n      <td>825</td>\n      <td>0.540400</td>\n      <td>0.638961</td>\n      <td>0.840000</td>\n    </tr>\n    <tr>\n      <td>850</td>\n      <td>0.466400</td>\n      <td>0.648708</td>\n      <td>0.830000</td>\n    </tr>\n    <tr>\n      <td>875</td>\n      <td>0.408200</td>\n      <td>0.627656</td>\n      <td>0.840000</td>\n    </tr>\n    <tr>\n      <td>900</td>\n      <td>0.421500</td>\n      <td>0.637574</td>\n      <td>0.833333</td>\n    </tr>\n    <tr>\n      <td>925</td>\n      <td>0.449400</td>\n      <td>0.638013</td>\n      <td>0.840000</td>\n    </tr>\n    <tr>\n      <td>950</td>\n      <td>0.385100</td>\n      <td>0.592310</td>\n      <td>0.843333</td>\n    </tr>\n    <tr>\n      <td>975</td>\n      <td>0.324600</td>\n      <td>0.640922</td>\n      <td>0.816667</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>0.520500</td>\n      <td>0.623989</td>\n      <td>0.830000</td>\n    </tr>\n    <tr>\n      <td>1025</td>\n      <td>0.331300</td>\n      <td>0.678723</td>\n      <td>0.816667</td>\n    </tr>\n    <tr>\n      <td>1050</td>\n      <td>0.573600</td>\n      <td>0.676141</td>\n      <td>0.823333</td>\n    </tr>\n    <tr>\n      <td>1075</td>\n      <td>0.452300</td>\n      <td>0.661247</td>\n      <td>0.826667</td>\n    </tr>\n    <tr>\n      <td>1100</td>\n      <td>0.442500</td>\n      <td>0.652400</td>\n      <td>0.833333</td>\n    </tr>\n    <tr>\n      <td>1125</td>\n      <td>0.278900</td>\n      <td>0.652408</td>\n      <td>0.836667</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":54,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=1125, training_loss=0.6971992331610786, metrics={'train_runtime': 721.5364, 'train_samples_per_second': 12.473, 'train_steps_per_second': 1.559, 'total_flos': 2368190850048000.0, 'train_loss': 0.6971992331610786, 'epoch': 3.0})"},"metadata":{}}]},{"cell_type":"markdown","source":"As we can see it still train but probably we can achive a higher results with proper preprocessing.","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}